# Model Configuration
lstm:
  input_dim: 50
  hidden_dim: 128
  num_layers: 3
  dropout: 0.3
  bidirectional: true
  use_attention: true

transformer:
  input_dim: 50
  d_model: 128
  nhead: 8
  num_encoder_layers: 4
  dim_feedforward: 512
  dropout: 0.3
  max_seq_length: 20
